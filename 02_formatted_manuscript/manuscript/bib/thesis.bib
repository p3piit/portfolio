@online{bergonzoliOrdinalMixedEffectsRandom2024,
  title = {Ordinal {{Mixed-Effects Random Forest}}},
  author = {Bergonzoli, Giulia and Rossi, Lidia and Masci, Chiara},
  date = {2024-06-05},
  eprint = {2406.03130},
  eprinttype = {arXiv},
  eprintclass = {stat},
  doi = {10.48550/arXiv.2406.03130},
  abstract = {We propose an innovative statistical method, called Ordinal Mixed-Effect Random Forest (OMERF), that extends the use of random forest to the analysis of hierarchical data and ordinal responses. The model preserves the flexibility and ability of modeling complex patterns of both categorical and continuous variables, typical of tree-based ensemble methods, and, at the same time, takes into account the structure of hierarchical data, modeling the dependence structure induced by the grouping and allowing statistical inference at all data levels. A simulation study is conducted to validate the performance of the proposed method and to compare it to the one of other state-of-the art models. The application of OMERF is exemplified in a case study focusing on predicting students performances using data from the Programme for International Student Assessment (PISA) 2022. The model identifies discriminating student characteristics and estimates the school-effect.},
  pubstate = {prepublished},
  keywords = {Statistics - Machine Learning,Statistics - Methodology},
  file = {files/97/Bergonzoli et al. - 2024 - Ordinal Mixed-Effects Random Forest.pdf;files/98/2406.html}
}

@online{bojicHierarchicalEvaluationFramework2023,
  title = {Hierarchical {{Evaluation Framework}}: {{Best Practices}} for {{Human Evaluation}}},
  shorttitle = {Hierarchical {{Evaluation Framework}}},
  author = {Bojic, Iva and Chen, Jessica and Chang, Si Yuan and Ong, Qi Chwen and Joty, Shafiq and Car, Josip},
  date = {2023-10-12},
  eprint = {2310.01917},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2310.01917},
  abstract = {Human evaluation plays a crucial role in Natural Language Processing (NLP) as it assesses the quality and relevance of developed systems, thereby facilitating their enhancement. However, the absence of widely accepted human evaluation metrics in NLP hampers fair comparisons among different systems and the establishment of universal assessment standards. Through an extensive analysis of existing literature on human evaluation metrics, we identified several gaps in NLP evaluation methodologies. These gaps served as motivation for developing our own hierarchical evaluation framework. The proposed framework offers notable advantages, particularly in providing a more comprehensive representation of the NLP system's performance. We applied this framework to evaluate the developed Machine Reading Comprehension system, which was utilized within a human-AI symbiosis model. The results highlighted the associations between the quality of inputs and outputs, underscoring the necessity to evaluate both components rather than solely focusing on outputs. In future work, we will investigate the potential time-saving benefits of our proposed framework for evaluators assessing NLP systems.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computation and Language,Computer Science - Human-Computer Interaction},
  file = {files/60/Bojic et al. - 2023 - Hierarchical Evaluation Framework Best Practices for Human Evaluation.pdf;files/61/2310.html}
}

@article{breslowApproximateInferenceGeneralized1993,
  title = {Approximate {{Inference}} in {{Generalized Linear Mixed Models}}},
  author = {Breslow, N. E. and Clayton, D. G.},
  date = {1993-03},
  journaltitle = {Journal of the American Statistical Association},
  shortjournal = {Journal of the American Statistical Association},
  volume = {88},
  number = {421},
  pages = {9--25},
  issn = {0162-1459, 1537-274X},
  doi = {10.1080/01621459.1993.10594284},
  langid = {english},
  file = {files/161/BreslowClayton(1993).pdf}
}

@article{capitaineRandomForestsHighdimensional2021,
  title = {Random Forests for High-Dimensional Longitudinal Data},
  author = {Capitaine, Louis and Genuer, Robin and Thiébaut, Rodolphe},
  date = {2021-01},
  journaltitle = {Statistical Methods in Medical Research},
  shortjournal = {Stat Methods Med Res},
  volume = {30},
  number = {1},
  pages = {166--184},
  issn = {0962-2802, 1477-0334},
  doi = {10.1177/0962280220946080},
  abstract = {Random forests are one of the state-of-the-art supervised machine learning methods and achieve good performance in high-dimensional settings where p, the number of predictors, is much larger than n, the number of observations. Repeated measurements provide, in general, additional information, hence they are worth accounted especially when analyzing high-dimensional data. Tree-based methods have already been adapted to clustered and longitudinal data by using a semi-parametric mixed effects model, in which the non-parametric part is estimated using regression trees or random forests. We propose a general approach of random forests for high-dimensional longitudinal data. It includes a flexible stochastic model which allows the covariance structure to vary over time. Furthermore, we introduce a new method which takes intra-individual covariance into consideration to build random forests. Through simulation experiments, we then study the behavior of different estimation methods, especially in the context of high-dimensional data. Finally, the proposed method has been applied to an HIV vaccine trial including 17 HIV-infected patients with 10 repeated measurements of 20,000 gene transcripts and blood concentration of human immunodeficiency virus RNA. The approach selected 21 gene transcripts for which the association with HIV viral load was fully relevant and consistent with results observed during primary infection.},
  langid = {english},
  note = {[TLDR] A new method which takes intra-individual covariance into consideration to build random forests for high-dimensional longitudinal data is introduced and applied to an HIV vaccine trial including 17 HIV-infected patients with 10 repeated measurements of 20,000 gene transcripts and blood concentration of human immunodeficiency virus RNA.},
  file = {files/54/Capitaine et al. - 2021 - Random forests for high-dimensional longitudinal data.pdf}
}

@online{crane-droeschSemiparametricPanelData2017,
  title = {Semiparametric Panel Data Models Using Neural Networks},
  author = {Crane-Droesch, Andrew},
  date = {2017-05-18},
  eprint = {1702.06512},
  eprinttype = {arXiv},
  eprintclass = {stat},
  doi = {10.48550/arXiv.1702.06512},
  abstract = {This paper presents an estimator for semiparametric models that uses a feed-forward neural network to fit the nonparametric component. Unlike many methodologies from the machine learning literature, this approach is suitable for longitudinal/panel data. It provides unbiased estimation of the parametric component of the model, with associated confidence intervals that have near-nominal coverage rates. Simulations demonstrate (1) efficiency, (2) that parametric estimates are unbiased, and (3) coverage properties of estimated intervals. An application section demonstrates the method by predicting county-level corn yield using daily weather data from the period 1981-2015, along with parametric time trends representing technological change. The method is shown to out-perform linear methods such as OLS and ridge/lasso, as well as random forest. The procedures described in this paper are implemented in the R package panelNNET.},
  pubstate = {prepublished},
  keywords = {Statistics - Applications},
  file = {files/154/Crane-Droesch - 2017 - Semiparametric panel data models using neural networks.pdf;files/155/1702.html}
}

@article{dottavianoMissingRandomEffects2022,
  title = {On Missing Random Effects in Machine Learning},
  author = {D’Ottaviano, Fabio and Yang, Wenzhao},
  date = {2022-11-02},
  journaltitle = {Communications in Statistics - Simulation and Computation},
  shortjournal = {Communications in Statistics - Simulation and Computation},
  volume = {51},
  number = {11},
  pages = {6320--6331},
  issn = {0361-0918, 1532-4141},
  doi = {10.1080/03610918.2020.1801729},
  abstract = {Abstract The large availability of undesigned data, a by-product of chemical industrial research and manufacturing, makes it attractive the venturesome use of machine learning for its plug-and-play appeal in attempt to extract value out of this data. Often this type of data does not only reflect the response to controlled variation but also to that caused by random effects. Thus, machine learning based models in this industry may easily miss active random effects out. This study shows by simulation the effect of missing a random effect via machine learning — vs. including it properly via mixed models as a benchmark — in a context commonly encountered in the chemical industry — mixture experiments with process variables — and as a function of relative cluster size, total variance, proportion of variance attributed to the random effect, and data size. Simulation was employed for it allows the comparison — missing vs. not missing random effects — to be made clear and in a simple manner while avoiding unwanted confounders found in real world data. Besides the long-established fact that machine learning performs better the larger the size of the data, it was also observed that data lacking due specificity — i.e. without clustering information — causes critical prediction biases regardless the data size.},
  langid = {english}
}

@article{fokkemaDetectingTreatmentsubgroupInteractions2018,
  title = {Detecting Treatment-Subgroup Interactions in Clustered Data with Generalized Linear Mixed-Effects Model Trees},
  author = {Fokkema, M. and Smits, N. and Zeileis, A. and Hothorn, T. and Kelderman, H.},
  date = {2018-10},
  journaltitle = {Behavior Research Methods},
  shortjournal = {Behav Res},
  volume = {50},
  number = {5},
  pages = {2016--2034},
  issn = {1554-3528},
  doi = {10.3758/s13428-017-0971-x},
  langid = {english},
  file = {files/25/downloadSupplement.txt;files/26/Fitting GLMM trees using R package glmertree.pdf;files/3/Fokkema et al. - 2018 - Detecting treatment-subgroup interactions in clustered data with generalized linear mixed-effects mo.pdf}
}

@article{fokkemaGeneralizedLinearMixedmodel2021,
  title = {Generalized Linear Mixed-Model ({{GLMM}}) Trees: {{A}} Flexible Decision-Tree Method for Multilevel and Longitudinal Data},
  shorttitle = {Generalized Linear Mixed-Model ({{GLMM}}) Trees},
  author = {Fokkema, Marjolein and Edbrooke-Childs, Julian and Wolpert, Miranda},
  date = {2021-04-03},
  journaltitle = {Psychotherapy Research},
  shortjournal = {Psychotherapy Research},
  volume = {31},
  number = {3},
  pages = {329--341},
  issn = {1050-3307, 1468-4381},
  doi = {10.1080/10503307.2020.1785037},
  abstract = {Method: To illustrate, we apply GLMM trees to a dataset of 3,256 young people (mean age 11.33, 48\% girls) receiving treatment at one of several mental-health service providers in the UK. Two treatment outcomes (mental-health difficulties scores corrected for baseline) were regressed on 18 demographic, case and severity characteristics at baseline. We compared the performance of GLMM trees with that of traditional GLMMs and random forests. Results: GLMM trees yielded modest predictive accuracy, with cross-validated multiple R values of .18 and .25. Predictive accuracy did not differ significantly from that of traditional GLMMs and random forests, while GLMM trees required evaluation of a lower number of variables. Conclusion: GLMM trees provide a useful data-analytic tool for clinical prediction problems. The supplemental material provides a tutorial for replicating the GLMM tree analyses in R.},
  langid = {english},
  file = {files/5/Fokkema et al. - 2021 - Generalized linear mixed-model (GLMM) trees A flexible decision-tree method for multilevel and long.pdf}
}

@article{fontanaPerformingLearningAnalytics2021,
  title = {Performing {{Learning Analytics}} via {{Generalised Mixed-Effects Trees}}},
  author = {Fontana, Luca and Masci, Chiara and Ieva, Francesca and Paganoni, Anna Maria},
  date = {2021-07},
  journaltitle = {Data},
  volume = {6},
  number = {7},
  pages = {74},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2306-5729},
  doi = {10.3390/data6070074},
  abstract = {Nowadays, the importance of educational data mining and learning analytics in higher education institutions is being recognised. The analysis of university careers and of student dropout prediction is one of the most studied topics in the area of learning analytics. From the perspective of estimating the likelihood of a student dropping out, we propose an innovative statistical method that is a generalisation of mixed-effects trees for a response variable in the exponential family: generalised mixed-effects trees (GMET). We performed a simulation study in order to validate the performance of our proposed method and to compare GMET to classical models. In the case study, we applied GMET to model undergraduate student dropout in different courses at Politecnico di Milano. The model was able to identify discriminating student characteristics and estimate the effect of each degree-based course on the probability of student dropout.},
  langid = {english},
  keywords = {academic data,learning analytics,mixed-effects models,regression and classification trees,student dropout},
  file = {files/147/Fontana et al. - 2021 - Performing Learning Analytics via Generalised Mixed-Effects Trees.pdf}
}

@book{gelmanDataAnalysisUsing2006,
  title = {Data {{Analysis Using Regression}} and {{Multilevel}}/{{Hierarchical Models}}},
  author = {Gelman, Andrew and Hill, Jennifer},
  date = {2006-12-18},
  edition = {1},
  publisher = {Cambridge University Press},
  doi = {10.1017/CBO9780511790942},
  abstract = {Data Analysis Using Regression and Multilevel/Hierarchical Models, first published in 2007, is a comprehensive manual for the applied researcher who wants to perform data analysis using linear and nonlinear regression and multilevel models. The book introduces a wide variety of models, whilst at the same time instructing the reader in how to fit these models using available software packages. The book illustrates the concepts by working through scores of real data examples that have arisen from the authors' own applied research, with programming codes provided for each one. Topics covered include causal inference, including regression, poststratification, matching, regression discontinuity, and instrumental variables, as well as multilevel logistic regression and missing-data imputation. Practical tips regarding building, fitting, and understanding are provided throughout.},
  isbn = {978-0-521-86706-1 978-0-521-68689-1 978-0-511-79094-2}
}

@article{gottardMixedeffectModelsTrees2023,
  title = {Mixed-Effect Models with Trees},
  author = {Gottard, Anna and Vannucci, Giulia and Grilli, Leonardo and Rampichini, Carla},
  date = {2023-06},
  journaltitle = {Advances in Data Analysis and Classification},
  shortjournal = {Adv Data Anal Classif},
  volume = {17},
  number = {2},
  pages = {431--461},
  issn = {1862-5347, 1862-5355},
  doi = {10.1007/s11634-022-00509-3},
  abstract = {Tree-based regression models are a class of statistical models for predicting continuous response variables when the shape of the regression function is unknown. They naturally take into account both non-linearities and interactions. However, they struggle with linear and quasi-linear effects and assume iid data. This article proposes two new algorithms for jointly estimating an interpretable predictive mixed-effect model with two components: a linear part, capturing the main effects, and a non-parametric component consisting of three trees for capturing non-linearities and interactions among individual-level predictors, among cluster-level predictors or cross-level. The first proposed algorithm focuses on prediction. The second one is an extension which implements a post-selection inference strategy to provide valid inference. The performance of the two algorithms is validated via Monte Carlo studies. An application on INVALSI data illustrates the potentiality of the proposed approach.},
  langid = {english},
  file = {files/6/Gottard et al. - 2023 - Mixed-effect models with trees.pdf}
}

@article{gottardMixedeffectModelsTrees2023a,
  title = {Mixed-Effect Models with Trees},
  author = {Gottard, Anna and Vannucci, Giulia and Grilli, Leonardo and Rampichini, Carla},
  date = {2023-06},
  journaltitle = {Advances in Data Analysis and Classification},
  shortjournal = {Adv Data Anal Classif},
  volume = {17},
  number = {2},
  pages = {431--461},
  issn = {1862-5347, 1862-5355},
  doi = {10.1007/s11634-022-00509-3},
  abstract = {Abstract                            Tree-based regression models are a class of statistical models for predicting continuous response variables when the shape of the regression function is unknown. They naturally take into account both non-linearities and interactions. However, they struggle with linear and quasi-linear effects and assume               iid               data. This article proposes two new algorithms for jointly estimating an interpretable predictive mixed-effect model with two components: a linear part, capturing the main effects, and a non-parametric component consisting of three trees for capturing non-linearities and interactions among individual-level predictors, among cluster-level predictors or cross-level. The first proposed algorithm focuses on prediction. The second one is an extension which implements a post-selection inference strategy to provide valid inference. The performance of the two algorithms is validated via Monte Carlo studies. An application on INVALSI data illustrates the potentiality of the proposed approach.},
  langid = {english},
  file = {files/50/Gottard et al. - 2023 - Mixed-effect models with trees.pdf}
}

@article{guoGroupInferenceHigh2021,
  title = {Group Inference in High Dimensions with Applications to Hierarchical Testing},
  author = {Guo, Zijian and Renaux, Claude and Bühlmann, Peter and Cai, Tony},
  date = {2021},
  journaltitle = {Electronic Journal of Statistics},
  shortjournal = {Electron. J. Stat.},
  volume = {15},
  number = {2},
  pages = {6633--6676},
  publisher = {Institute of Mathematical Statistics},
  issn = {1935-7524},
  doi = {10.1214/21-EJS1955},
  abstract = {High-dimensional group inference is an essential part of statistical methods for analysing complex data sets, including hierarchical testing, tests of interaction, detection of heterogeneous treatment effects and inference for local heritability. Group inference in regression models can be measured with respect to a weighted quadratic functional of the regression sub-vector corresponding to the group. Asymptotically unbiased estimators of these weighted quadratic functionals are constructed and a novel procedure using these estimators for inference is proposed. We derive its asymptotic Gaussian distribution which enables the construction of asymptotically valid confidence intervals and tests which perform well in terms of length or power. The proposed test is computationally efficient even for a large group, statistically valid for any group size and achieving good power performance for testing large groups with many small regression coefficients. We apply the methodology to several interesting statistical problems and demonstrate its strength and usefulness on simulated and real data. © 2021, Institute of Mathematical Statistics. All rights reserved.},
  langid = {english},
  keywords = {debiasing Lasso,Heterogeneous effects,interaction test,local her-itability,partial regression},
  file = {files/56/Guo et al. - 2021 - Group inference in high dimensions with applications to hierarchical testing.pdf;files/57/85130365296.html}
}

@article{hajjemGeneralizedMixedEffects2017,
  title = {Generalized Mixed Effects Regression Trees},
  author = {Hajjem, Ahlem and Larocque, Denis and Bellavance, François},
  date = {2017-07},
  journaltitle = {Statistics \& Probability Letters},
  shortjournal = {Statistics \& Probability Letters},
  volume = {126},
  pages = {114--118},
  issn = {01677152},
  doi = {10.1016/j.spl.2017.02.033},
  abstract = {This paper presents generalized mixed effects regression trees, an extension of mixed effects regression trees to other types of outcomes. A simulation shows that the proposed method provides substantial improvements over standard trees when data are correlated.},
  langid = {english},
  file = {files/9/Hajjem et al. - 2017 - Generalized mixed effects regression trees.pdf}
}

@article{hajjemMixedeffectsRandomForest2014,
  title = {Mixed-Effects Random Forest for Clustered Data},
  author = {Hajjem, Ahlem and Bellavance, François and Larocque, Denis},
  date = {2014-06-03},
  journaltitle = {Journal of Statistical Computation and Simulation},
  shortjournal = {Journal of Statistical Computation and Simulation},
  volume = {84},
  number = {6},
  pages = {1313--1328},
  issn = {0094-9655, 1563-5163},
  doi = {10.1080/00949655.2012.741599},
  langid = {english},
  file = {files/8/Hajjem et al. - 2014 - Mixed-effects random forest for clustered data.pdf}
}

@article{hajjemMixedEffectsRegression2011,
  title = {Mixed Effects Regression Trees for Clustered Data},
  author = {Hajjem, Ahlem and Bellavance, François and Larocque, Denis},
  date = {2011-04},
  journaltitle = {Statistics \& Probability Letters},
  shortjournal = {Statistics \& Probability Letters},
  volume = {81},
  number = {4},
  pages = {451--459},
  issn = {01677152},
  doi = {10.1016/j.spl.2010.12.003},
  abstract = {This paper presents an extension of the standard regression tree method to clustered data. Previous works extending tree methods to accommodate correlated data are mainly based on the multivariate repeated-measures approach. We propose a ‘‘mixed effects regression tree’’ method where the correlated observations are viewed as nested within clusters rather than as vectors of multivariate repeated responses. The proposed method can handle unbalanced clusters, allows observations within clusters to be split, and can incorporate random effects and observation-level covariates. We implemented the proposed method using a standard tree algorithm within the framework of the expectation-maximization (EM) algorithm. The simulation results show that the proposed regression tree method provides substantial improvements over standard trees when the random effects are non negligible. A real data example is used to illustrate the method.},
  langid = {english},
  file = {files/7/Hajjem et al. - 2011 - Mixed effects regression trees for clustered data.pdf}
}

@book{hastieElementsStatisticalLearning2009,
  title = {The {{Elements}} of {{Statistical Learning}}},
  author = {Hastie, Trevor and Tibshirani, Robert and Friedman, Jerome},
  date = {2009},
  series = {Springer {{Series}} in {{Statistics}}},
  publisher = {Springer New York},
  location = {New York, NY},
  doi = {10.1007/978-0-387-84858-7},
  isbn = {978-0-387-84857-0 978-0-387-84858-7}
}

@article{huPredictionsMachineLearning2022,
  title = {Predictions of Machine Learning with Mixed-Effects in Analyzing Longitudinal Data under Model Misspecification},
  author = {Hu, Shuwen and Wang, You-Gan and Drovandi, Christopher and Cao, Taoyun},
  date = {2022-09-29},
  journaltitle = {Statistical Methods \& Applications},
  doi = {10.1007/s10260-022-00658-x},
  abstract = {See the Influence \& Quality of a Paper Without Reading it.},
  langid = {english},
  file = {files/107/Hu et al. - 2022 - Predictions of machine learning with mixed-effects in analyzing longitudinal data under model misspe.pdf}
}

@article{huReviewLongitudinalData2023,
  title = {A Review on Longitudinal Data Analysis with Random Forest},
  author = {Hu, Jianchang and Szymczak, Silke},
  date = {2023-03-19},
  journaltitle = {Briefings in Bioinformatics},
  volume = {24},
  number = {2},
  pages = {bbad002},
  issn = {1467-5463, 1477-4054},
  doi = {10.1093/bib/bbad002},
  abstract = {Abstract             In longitudinal studies variables are measured repeatedly over time, leading to clustered and correlated observations. If the goal of the study is to develop prediction models, machine learning approaches such as the powerful random forest (RF) are often promising alternatives to standard statistical methods, especially in the context of high-dimensional data. In this paper, we review extensions of the standard RF method for the purpose of longitudinal data analysis. Extension methods are categorized according to the data structures for which they are designed. We consider both univariate and multivariate response longitudinal data and further categorize the repeated measurements according to whether the time effect is relevant. Even though most extensions are proposed for low-dimensional data, some can be applied to high-dimensional data. Information of available software implementations of the reviewed extensions is also given. We conclude with discussions on the limitations of our review and some future research directions.},
  langid = {english},
  file = {files/46/Hu and Szymczak - 2023 - A review on longitudinal data analysis with random forest.pdf}
}

@article{huReviewLongitudinalData2023a,
  title = {A Review on Longitudinal Data Analysis with Random Forest},
  author = {Hu, Jianchang and Szymczak, Silke},
  date = {2023-03-19},
  journaltitle = {Briefings in Bioinformatics},
  volume = {24},
  number = {2},
  pages = {bbad002},
  issn = {1467-5463, 1477-4054},
  doi = {10.1093/bib/bbad002},
  abstract = {Abstract             In longitudinal studies variables are measured repeatedly over time, leading to clustered and correlated observations. If the goal of the study is to develop prediction models, machine learning approaches such as the powerful random forest (RF) are often promising alternatives to standard statistical methods, especially in the context of high-dimensional data. In this paper, we review extensions of the standard RF method for the purpose of longitudinal data analysis. Extension methods are categorized according to the data structures for which they are designed. We consider both univariate and multivariate response longitudinal data and further categorize the repeated measurements according to whether the time effect is relevant. Even though most extensions are proposed for low-dimensional data, some can be applied to high-dimensional data. Information of available software implementations of the reviewed extensions is also given. We conclude with discussions on the limitations of our review and some future research directions.},
  langid = {english},
  file = {files/65/Hu and Szymczak - 2023 - A review on longitudinal data analysis with random forest.pdf}
}

@book{jamesIntroductionStatisticalLearning2021,
  title = {An {{Introduction}} to {{Statistical Learning}}: With {{Applications}} in {{R}}},
  shorttitle = {An {{Introduction}} to {{Statistical Learning}}},
  author = {James, Gareth and Witten, Daniela and Hastie, Trevor and Tibshirani, Robert},
  date = {2021},
  series = {Springer {{Texts}} in {{Statistics}}},
  publisher = {Springer US},
  location = {New York, NY},
  doi = {10.1007/978-1-0716-1418-1},
  isbn = {978-1-0716-1417-4 978-1-0716-1418-1},
  langid = {english}
}

@article{jingRegressionTreeMethod2024,
  title = {A Regression Tree Method for Longitudinal and Clustered Data with Multivariate Responses},
  author = {Jing, Wenbo and Simonoff, Jeffrey S.},
  date = {2024-03-03},
  journaltitle = {Journal of Statistical Computation and Simulation},
  shortjournal = {Journal of Statistical Computation and Simulation},
  volume = {94},
  number = {4},
  pages = {820--842},
  issn = {0094-9655, 1563-5163},
  doi = {10.1080/00949655.2023.2273966},
  abstract = {In this paper, we propose a tree-based method called Multivariate RE-EM tree, which combines the regression tree and the linear mixed effects model for modeling multivariate response longitudinal or clustered data. The Multivariate RE-EM tree method estimates a population-level single tree structure that is driven by the multiple responses simultaneously and object-level random effects for each response variable, where correlation between the response variables and between the associated random effects are each allowed. Through simulation studies, we verify the advantage of the Multivariate RE-EM tree over the use of multiple univariate RE-EM trees and the Multivariate Regression Tree. We apply the Multivariate RE-EM tree to analyze a real data set that contains multidimensional nonfinancial characteristics of poverty of different countries as responses, and various potential causes of poverty as predictors.},
  langid = {english},
  file = {files/72/Jing and Simonoff - 2024 - A regression tree method for longitudinal and clustered data with multivariate responses.pdf}
}

@article{liangLongitudinalDataAnalysis1986,
  title = {Longitudinal Data Analysis Using Generalized Linear Models},
  author = {Liang, Kung-Yee and Zeger, Scott L.},
  date = {1986},
  journaltitle = {Biometrika},
  shortjournal = {Biometrika},
  volume = {73},
  number = {1},
  pages = {13--22},
  issn = {0006-3444, 1464-3510},
  doi = {10.1093/biomet/73.1.13},
  langid = {english}
}

@article{linNewMultilevelCART2019,
  title = {A {{New Multilevel CART Algorithm}} for {{Multilevel Data}} with {{Binary Outcomes}}},
  author = {Lin, Shuqiong and Luo, Wen},
  date = {2019},
  journaltitle = {Multivariate Behavioral Research},
  shortjournal = {Multivariate Behav Res},
  volume = {54},
  number = {4},
  eprint = {30644764},
  eprinttype = {pubmed},
  pages = {578--592},
  issn = {1532-7906},
  doi = {10.1080/00273171.2018.1552555},
  abstract = {The multilevel logistic regression model (M-logit) is the standard model for modeling multilevel data with binary outcomes. However, many assumptions and restrictions should be considered when applying this model for unbiased estimation. To overcome these limitations, we proposed a multilevel CART (M-CART) algorithm which combines the M-logit and single level CART (S-CART) within the framework of the expectation-maximization. Simulation results showed that the proposed M-CART provided substantial improvements on classification accuracy, sensitivity, and specific over the M-logit, S-CART, and single level logistic regression model when modeling multilevel data with binary outcomes. This benefit of using M-CART was consistently found across different conditions of sample size, intra-class correlation, and when relationships between predictors and outcomes were nonlinear and nonadditive.},
  langid = {english},
  keywords = {Algorithms,Computer Simulation,Humans,Models Statistical,Multilevel CART,multilevel data with binary outcomes,multilevel logistic regression model,Regression Analysis,Sample Size}
}

@article{manginoPredictionMixedEffects2021,
  title = {Prediction {{With Mixed Effects Models}}: {{A Monte Carlo Simulation Study}}},
  shorttitle = {Prediction {{With Mixed Effects Models}}},
  author = {Mangino, Anthony A. and Finch, W. Holmes},
  date = {2021-12},
  journaltitle = {Educational and Psychological Measurement},
  shortjournal = {Educ Psychol Meas},
  volume = {81},
  number = {6},
  eprint = {34565818},
  eprinttype = {pubmed},
  pages = {1118--1142},
  issn = {0013-1644},
  doi = {10.1177/0013164421992818},
  abstract = {Oftentimes in many fields of the social and natural sciences, data are obtained within a nested structure (e.g., students within schools). To effectively analyze data with such a structure, multilevel models are frequently employed. The present study utilizes a Monte Carlo simulation to compare several novel multilevel classification algorithms across several varied data conditions for the purpose of prediction. Among these models, the panel neural network and Bayesian generalized mixed effects model (multilevel Bayes) consistently yielded the highest prediction accuracy in test data across nearly all data conditions.},
  pmcid = {PMC8451021},
  file = {files/160/Mangino and Finch - 2021 - Prediction With Mixed Effects Models A Monte Carlo Simulation Study.pdf}
}

@article{nguforMixedEffectMachine2019,
  title = {Mixed Effect Machine Learning: {{A}} Framework for Predicting Longitudinal Change in Hemoglobin {{A1c}}},
  shorttitle = {Mixed Effect Machine Learning},
  author = {Ngufor, Che and Van Houten, Holly and Caffo, Brian S. and Shah, Nilay D. and McCoy, Rozalina G.},
  date = {2019-01},
  journaltitle = {Journal of Biomedical Informatics},
  shortjournal = {J Biomed Inform},
  volume = {89},
  eprint = {30189255},
  eprinttype = {pubmed},
  pages = {56--67},
  issn = {1532-0480},
  doi = {10.1016/j.jbi.2018.09.001},
  abstract = {Accurate and reliable prediction of clinical progression over time has the potential to improve the outcomes of chronic disease. The classical approach to analyzing longitudinal data is to use (generalized) linear mixed-effect models (GLMM). However, linear parametric models are predicated on assumptions, which are often difficult to verify. In contrast, data-driven machine learning methods can be applied to derive insight from the raw data without a priori assumptions. However, the underlying theory of most machine learning algorithms assume that the data is independent and identically distributed, making them inefficient for longitudinal supervised learning. In this study, we formulate an analytic framework, which integrates the random-effects structure of GLMM into non-linear machine learning models capable of exploiting temporal heterogeneous effects, sparse and varying-length patient characteristics inherent in longitudinal data. We applied the derived mixed-effect machine learning (MEml) framework to predict longitudinal change in glycemic control measured by hemoglobin A1c (HbA1c) among well controlled adults with type 2 diabetes. Results show that MEml is competitive with traditional GLMM, but substantially outperformed standard machine learning models that do not account for random-effects. Specifically, the accuracy of MEml in predicting glycemic change at the 1st, 2nd, 3rd, and 4th clinical visits in advanced was 1.04, 1.08, 1.11, and 1.14 times that of the gradient boosted model respectively, with similar results for the other methods. To further demonstrate the general applicability of MEml, a series of experiments were performed using real publicly available and synthetic data sets for accuracy and robustness. These experiments reinforced the superiority of MEml over the other methods. Overall, results from this study highlight the importance of modeling random-effects in machine learning approaches based on longitudinal data. Our MEml method is highly resistant to correlated data, readily accounts for random-effects, and predicts change of a longitudinal clinical outcome in real-world clinical settings with high accuracy.},
  langid = {english},
  pmcid = {PMC6495570},
  keywords = {Adult,Algorithms,Diabetes Mellitus Type 2,Disease Progression,Glycated Hemoglobin,Glycemic control,Glycosylated hemoglobin,Humans,Longitudinal Studies,Longitudinal supervised learning,Machine learning,Machine Learning,Random-effects,Type 2 diabetes},
  file = {files/89/Ngufor et al. - 2019 - Mixed effect machine learning A framework for predicting longitudinal change in hemoglobin A1c.pdf}
}

@article{pellagattiGeneralizedMixedeffectsRandom2021,
  title = {Generalized Mixed-Effects Random Forest: {{A}} Flexible Approach to Predict University Student Dropout},
  shorttitle = {Generalized Mixed-Effects Random Forest},
  author = {Pellagatti, Massimo and Masci, Chiara and Ieva, Francesca and Paganoni, Anna M.},
  date = {2021},
  journaltitle = {Statistical Analysis and Data Mining: The ASA Data Science Journal},
  volume = {14},
  number = {3},
  pages = {241--257},
  issn = {1932-1872},
  doi = {10.1002/sam.11505},
  abstract = {We propose a new statistical method, called generalized mixed-effects random forest (GMERF), that extends the use of random forest to the analysis of hierarchical data, for any type of response variable in the exponential family. The method maintains the flexibility and the ability of modeling complex patterns within the data, typical of tree-based ensemble methods, and it can handle both continuous and discrete covariates. At the same time, GMERF takes into account the nested structure of hierarchical data, modeling the dependence structure that exists at the highest level of the hierarchy and allowing statistical inference on this structure. In the case study, we apply GMERF to Higher Education data to analyze the university student dropout phenomenon. We predict engineering student dropout probability by means of student-level information and considering the degree program students are enrolled in as grouping factor.},
  langid = {english},
  keywords = {generalized models,hierarchical data,random forest,university students dropout},
  file = {files/94/Pellagatti et al. - 2021 - Generalized mixed-effects random forest A flexible approach to predict university student dropout.pdf;files/95/sam.html}
}

@online{rabinowiczTreesBasedModelsCorrelated2021,
  title = {Trees-{{Based Models}} for {{Correlated Data}}},
  author = {Rabinowicz, Assaf and Rosset, Saharon},
  date = {2021-08-06},
  eprint = {2102.08114},
  eprinttype = {arXiv},
  eprintclass = {stat},
  doi = {10.48550/arXiv.2102.08114},
  abstract = {This paper presents a new approach for trees-based regression, such as simple regression tree, random forest and gradient boosting, in settings involving correlated data. We show the problems that arise when implementing standard trees-based regression models, which ignore the correlation structure. Our new approach explicitly takes the correlation structure into account in the splitting criterion, stopping rules and fitted values in the leaves, which induces some major modifications of standard methodology. The superiority of our new approach over trees-based models that do not account for the correlation is supported by simulation experiments and real data analyses.},
  pubstate = {prepublished},
  keywords = {Statistics - Machine Learning,Statistics - Methodology},
  file = {files/85/Rabinowicz and Rosset - 2021 - Trees-Based Models for Correlated Data.pdf;files/86/2102.html}
}

@article{registerComparingEffectivenessStandard2025,
  title = {Comparing the {{Effectiveness}} of {{Standard}} vs. {{Multilevel Machine Learning Algorithms}} on {{Hierarchical Data}}},
  author = {Register, Brennan},
  date = {2025},
  eprint = {1903/34077},
  eprinttype = {hdl},
  abstract = {This dissertation explored the performance of standard and multilevel machine learning classification algorithms on hierarchical datasets, which are prevalent in educational research due to multistage sampling techniques (e.g., students nested within schools). Hierarchical data pose unique analytical challenges (e.g., nonindependence of data), often requiring specialized approaches. While multilevel modeling is well-established in inferential contexts, its potential in predictive scenarios had been largely underexplored. Through a Monte Carlo simulation and empirical analyses using data from the Maryland Longitudinal Data System (MLDS), this study evaluated the suitability of standard and multilevel algorithms. Results revealed that multilevel models offered slight advantages in high residual level-2 variance settings, effectively capturing cluster-level dependencies and providing stable predictions. Standard models performed well in low residual level-2 variance contexts, while standard models incorporating cluster IDs as fixed effects performed comparably to multilevel models under many conditions, including high residual level-2 variance scenarios. However, this approach was only feasible when training and testing clusters overlapped, highlighting limitations in generalizing predictions to unseen clusters. In an empirical analysis addressing class imbalance, Logistic Regression and GLMM exhibited the highest sensitivity for identifying STEM completers when training and testing clusters overlapped while Neural Nets and XGBoost demonstrated better performance in identifying the minority class when training and testing clusters were distinct. These findings highlighted the complexity of predictive modeling for hierarchical data and provided insights for prediction tasks in educational research.},
  langid = {english},
  file = {files/31/34077.html}
}

@article{saldittGradientTreeBoosting2023,
  title = {Gradient {{Tree Boosting}} for {{Hierarchical Data}}},
  author = {Salditt, Marie and Humberg, Sarah and Nestler, Steffen},
  date = {2023-09-03},
  journaltitle = {Multivariate Behavioral Research},
  volume = {58},
  number = {5},
  eprint = {36602080},
  eprinttype = {pubmed},
  pages = {911--937},
  publisher = {Routledge},
  issn = {0027-3171},
  doi = {10.1080/00273171.2022.2146638},
  abstract = {Gradient tree boosting is a powerful machine learning technique that has shown good performance in predicting a variety of outcomes. However, when applied to hierarchical (e.g., longitudinal or clustered) data, the predictive performance of gradient tree boosting may be harmed by ignoring the hierarchical structure, and may be improved by accounting for it. Tree-based methods such as regression trees and random forests have already been extended to hierarchical data settings by combining them with the linear mixed effects model (MEM). In the present article, we add to this literature by proposing two algorithms to estimate a combination of the MEM and gradient tree boosting. We report on two simulation studies that (i) investigate the predictive performance of the two MEM boosting algorithms and (ii) compare them to standard gradient tree boosting, standard random forest, and other existing methods for hierarchical data (MEM, MEM random forests, model-based boosting, Bayesian additive regression trees [BART]). We found substantial improvements in the predictive performance of our MEM boosting algorithms over standard boosting when the random effects were non-negligible. MEM boosting as well as BART showed a predictive performance similar to the correctly specified MEM (i.e., the benchmark model), and overall outperformed the model-based boosting and random forest approaches.},
  keywords = {atypical observations,gradient boosting,longitudinal data,Mixed effects models,regression trees},
  file = {files/42/Salditt et al. - 2023 - Gradient Tree Boosting for Hierarchical Data.pdf}
}

@article{schelldorferGLMMLassoAlgorithmHighDimensional2014,
  title = {{{GLMMLasso}}: {{An Algorithm}} for {{High-Dimensional Generalized Linear Mixed Models Using}} \$\textbackslash ell\_1\$-{{Penalization}}},
  shorttitle = {{{GLMMLasso}}},
  author = {Schelldorfer, Jürg and Meier, Lukas and Bühlmann, Peter},
  date = {2014-04-03},
  journaltitle = {Journal of Computational and Graphical Statistics},
  shortjournal = {Journal of Computational and Graphical Statistics},
  volume = {23},
  number = {2},
  pages = {460--477},
  issn = {1061-8600, 1537-2715},
  doi = {10.1080/10618600.2013.773239},
  langid = {english},
  file = {files/143/Schelldorfer et al. - 2014 - GLMMLasso An Algorithm for High-Dimensional Generalized Linear Mixed Models Using ℓ1 -Pe.pdf}
}

@article{selaREEMTreesData2012,
  title = {{{RE-EM}} Trees: A Data Mining Approach for Longitudinal and Clustered Data},
  shorttitle = {{{RE-EM}} Trees},
  author = {Sela, Rebecca J. and Simonoff, Jeffrey S.},
  date = {2012-02-01},
  journaltitle = {Machine Learning},
  shortjournal = {Mach Learn},
  volume = {86},
  number = {2},
  pages = {169--207},
  issn = {1573-0565},
  doi = {10.1007/s10994-011-5258-3},
  abstract = {Longitudinal data refer to the situation where repeated observations are available for each sampled object. Clustered data, where observations are nested in a hierarchical structure within objects (without time necessarily being involved) represent a similar type of situation. Methodologies that take this structure into account allow for the possibilities of systematic differences between objects that are not related to attributes and autocorrelation within objects across time periods. A standard methodology in the statistics literature for this type of data is the mixed effects model, where these differences between objects are represented by so-called “random effects” that are estimated from the data (population-level relationships are termed “fixed effects,” together resulting in a mixed effects model). This paper presents a methodology that combines the structure of mixed effects models for longitudinal and clustered data with the flexibility of tree-based estimation methods. We apply the resulting estimation method, called the RE-EM tree, to pricing in online transactions, showing that the RE-EM tree is less sensitive to parametric assumptions and provides improved predictive power compared to linear models with random effects and regression trees without random effects. We also apply it to a smaller data set examining accident fatalities, and show that the RE-EM tree strongly outperforms a tree without random effects while performing comparably to a linear model with random effects. We also perform extensive simulation experiments to show that the estimator improves predictive performance relative to regression trees without random effects and is comparable or superior to using linear models with random effects in more general situations.},
  langid = {english},
  keywords = {CART,Clustered data,Longitudinal data,Mixed effects model,Panel data,Random effects,Regression tree},
  file = {files/29/Sela and Simonoff - 2012 - RE-EM trees a data mining approach for longitudinal and clustered data.pdf}
}

@article{shahbaziHierarchicalDataModeling2025,
  title = {Hierarchical Data Modeling: {{A}} Systematic Comparison of Statistical, Tree-Based, and Neural Network Approaches},
  shorttitle = {Hierarchical Data Modeling},
  author = {Shahbazi, Marzieh Amiri and Azadeh-Fard, Nasibeh},
  date = {2025-09-01},
  journaltitle = {Machine Learning with Applications},
  shortjournal = {Machine Learning with Applications},
  volume = {21},
  pages = {100688},
  issn = {2666-8270},
  doi = {10.1016/j.mlwa.2025.100688},
  abstract = {Hierarchical modeling approaches have evolved significantly, yet comprehensive comparisons between fundamentally different methodological paradigms remain limited. This research presents a systematic comparative analysis of three distinct hierarchical modeling approaches: statistical (Hierarchical Mixed Model), tree-based (Hierarchical Random Forest), and neural (Hierarchical Neural Network). Based on the 2019 National Inpatient Sample — comprising more than seven million records from 4568 hospitals across four U.S. regions — the models were assessed for their ability to predict length of stay at the patient, hospital, and regional levels. The evaluation framework integrated quantitative metrics and qualitative factors, including analyses across varying sample sizes, simplified hierarchies, and a separate intensive-care dataset. Results demonstrate that tree-based approaches consistently outperform alternatives in predictive accuracy and explanation of variance while maintaining computational efficiency. These performance patterns remain generally consistent across sample sizes, simplified hierarchies, and the external dataset. Neural approaches excel at capturing group-level distinctions but require substantial computational resources and exhibit prediction bias. Statistical approaches offer rapid inference and interpretability but underperform in accuracy at intermediate hierarchical levels. Each model exhibits distinctive hierarchical information processing: neural models favor bottom-up flow, statistical models emphasize top-down constraints, and tree-based models achieve balanced integration. This research establishes practical guidelines for selecting appropriate hierarchical modeling approaches based on data characteristics, computational constraints, and analytical requirements, thereby advancing understanding of fundamental trade-offs in multilevel analysis.},
  keywords = {Comparative analysis,Computational efficiency,Healthcare data,Hierarchical modeling,Model selection,Multilevel analysis,Nested structures,Neural networks,Statistical models,Tree-based methods},
  file = {files/40/S2666827025000714.html}
}

@online{sigristGaussianProcessBoosting2024,
  title = {Gaussian {{Process Boosting}}},
  author = {Sigrist, Fabio},
  date = {2024-11-05},
  eprint = {2004.02653},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2004.02653},
  abstract = {We introduce a novel way to combine boosting with Gaussian process and mixed effects models. This allows for relaxing, first, the zero or linearity assumption for the prior mean function in Gaussian process and grouped random effects models in a flexible non-parametric way and, second, the independence assumption made in most boosting algorithms. The former is advantageous for prediction accuracy and for avoiding model misspecifications. The latter is important for efficient learning of the fixed effects predictor function and for obtaining probabilistic predictions. Our proposed algorithm is also a novel solution for handling high-cardinality categorical variables in tree-boosting. In addition, we present an extension that scales to large data using a Vecchia approximation for the Gaussian process model relying on novel results for covariance parameter inference. We obtain increased prediction accuracy compared to existing approaches on multiple simulated and real-world data sets.},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning,Statistics - Computation,Statistics - Machine Learning,Statistics - Methodology},
  file = {files/102/Sigrist - 2024 - Gaussian Process Boosting.pdf;files/103/2004.html}
}

@online{sigristLatentGaussianModel2022,
  title = {Latent {{Gaussian Model Boosting}}},
  author = {Sigrist, Fabio},
  date = {2022-07-25},
  eprint = {2105.08966},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2105.08966},
  abstract = {Latent Gaussian models and boosting are widely used techniques in statistics and machine learning. Tree-boosting shows excellent prediction accuracy on many data sets, but potential drawbacks are that it assumes conditional independence of samples, produces discontinuous predictions for, e.g., spatial data, and it can have difficulty with high-cardinality categorical variables. Latent Gaussian models, such as Gaussian process and grouped random effects models, are flexible prior models which explicitly model dependence among samples and which allow for efficient learning of predictor functions and for making probabilistic predictions. However, existing latent Gaussian models usually assume either a zero or a linear prior mean function which can be an unrealistic assumption. This article introduces a novel approach that combines boosting and latent Gaussian models to remedy the above-mentioned drawbacks and to leverage the advantages of both techniques. We obtain increased prediction accuracy compared to existing approaches in both simulated and real-world data experiments.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Computation,Statistics - Machine Learning,Statistics - Methodology},
  file = {files/12/Sigrist - 2022 - Latent Gaussian Model Boosting.pdf}
}

@book{snijdersMultilevelAnalysisIntroduction2012,
  title = {Multilevel Analysis: An Introduction to Basic and Advanced Multilevel Modeling},
  shorttitle = {Multilevel Analysis},
  author = {Snijders, Tom A. B. and Bosker, Roel J.},
  date = {2012},
  edition = {2. ed},
  publisher = {SAGE},
  location = {Los Angeles, Calif.},
  isbn = {978-1-84920-200-8 978-1-84920-201-5},
  langid = {english},
  pagetotal = {354},
  file = {files/132/Multilevel Analysis An Introduction to Basic and Advanced Multilevel Modeling (Professor Tom A.B. Snijders etc.) (Z-Library).pdf;files/136/Snijders and Bosker - 2012 - Multilevel analysis an introduction to basic and advanced multilevel modeling.pdf}
}

@article{speiserBiMMForestRandom2019,
  title = {{{BiMM}} Forest: {{A}} Random Forest Method for Modeling Clustered and Longitudinal Binary Outcomes},
  shorttitle = {{{BiMM}} Forest},
  author = {Speiser, Jaime Lynn and Wolf, Bethany J. and Chung, Dongjun and Karvellas, Constantine J. and Koch, David G. and Durkalski, Valerie L.},
  date = {2019-02-15},
  journaltitle = {Chemometrics and intelligent laboratory systems : an international journal sponsored by the Chemometrics Society},
  shortjournal = {Chemometr Intell Lab Syst},
  volume = {185},
  eprint = {31656362},
  eprinttype = {pubmed},
  pages = {122--134},
  issn = {0169-7439},
  doi = {10.1016/j.chemolab.2019.01.002},
  abstract = {Clustered binary outcomes and datasets with many predictor variables are frequently encountered in clinical research (e.g. longitudinal studies). Generalized linear mixed models (GLMMs) typically employed for clustered endpoints have challenges for some scenarios, particularly for complex datasets which contain many interactions among predictors and nonlinear predictors of outcome. We propose a new method called Binary Mixed Model (BiMM) forest, which combines random forest and GLMM methodology. BiMM forest offers a flexible and stable method which naturally models interactions among predictors and can be employed in the setting of clustered data. Simulation studies show that BiMM forest achieves similar or superior prediction accuracy compared to standard random forest, GLMMs and its tree counterpart (BiMM tree) for clustered binary outcomes. The method is applied to a real dataset from the Acute Liver Failure Study Group. BiMM forest offers an alternative method for modeling clustered binary outcomes which may be applied in myriad research settings.},
  pmcid = {PMC6813794},
  file = {files/150/Speiser et al. - 2019 - BiMM forest A random forest method for modeling clustered and longitudinal binary outcomes.pdf}
}

@article{speiserBiMMTreeDecision2020,
  title = {{{BiMM}} Tree: A Decision Tree Method for Modeling Clustered and Longitudinal Binary Outcomes},
  shorttitle = {{{BiMM}} Tree},
  author = {Speiser, Jaime Lynn and Wolf, Bethany J. and Chung, Dongjun and Karvellas, Constantine J. and Koch, David G. and Durkalski, Valerie L.},
  date = {2020-04-02},
  journaltitle = {Communications in Statistics - Simulation and Computation},
  shortjournal = {Communications in Statistics - Simulation and Computation},
  volume = {49},
  number = {4},
  pages = {1004--1023},
  issn = {0361-0918, 1532-4141},
  doi = {10.1080/03610918.2018.1490429},
  langid = {english},
  file = {files/152/Speiser et al. - 2020 - BiMM tree a decision tree method for modeling clustered and longitudinal binary outcomes.pdf}
}

@online{wundervaldHierarchicalEmbeddedBayesian2023,
  title = {Hierarchical {{Embedded Bayesian Additive Regression Trees}}},
  author = {Wundervald, Bruna and Parnell, Andrew and Domijan, Katarina},
  date = {2023-04-24},
  eprint = {2204.07207},
  eprinttype = {arXiv},
  eprintclass = {stat},
  doi = {10.48550/arXiv.2204.07207},
  abstract = {We propose a simple yet powerful extension of Bayesian Additive Regression Trees which we name Hierarchical Embedded BART (HE-BART). The model allows for random effects to be included at the terminal node level of a set of regression trees, making HE-BART a non-parametric alternative to mixed effects models which avoids the need for the user to specify the structure of the random effects in the model, whilst maintaining the prediction and uncertainty calibration properties of standard BART. Using simulated and real world examples, we demonstrate that this new extension yields superior predictions for many of the standard mixed effects models’ example data sets, and yet still provides consistent estimates of the random effect variances. In a future version of this paper, we outline its use in larger, more advanced data sets and structures.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning,Statistics - Methodology},
  file = {files/13/Wundervald et al. - 2023 - Hierarchical Embedded Bayesian Additive Regression Trees.pdf}
}

@book{wuNonparametricRegressionMethods2006,
  title = {Nonparametric Regression Methods for Longitudinal Data Analysis: Mixed-Effects Modeling Approaches},
  shorttitle = {Nonparametric Regression Methods for Longitudinal Data Analysis},
  author = {Wu, Hulin},
  namea = {Zhang, Jin-Ting},
  nameatype = {collaborator},
  date = {2006},
  series = {Wiley Series in Probability and Statistics},
  publisher = {Wiley-Interscience},
  location = {Hoboken, N.J},
  isbn = {978-0-471-48350-2 978-0-470-00966-6},
  langid = {english},
  pagetotal = {369},
}

@article{yangModelbasedClusteringHighdimensional2023,
  title = {Model-Based Clustering of High-Dimensional Longitudinal Data via Regularization},
  author = {Yang, Luoying and Wu, Tong Tong},
  date = {2023-06},
  journaltitle = {Biometrics},
  shortjournal = {Biometrics},
  volume = {79},
  number = {2},
  eprint = {35428983},
  eprinttype = {pubmed},
  pages = {761--774},
  issn = {1541-0420},
  doi = {10.1111/biom.13672},
  abstract = {We propose a model-based clustering method for high-dimensional longitudinal data via regularization in this paper. This study was motivated by the Trial of Activity in Adolescent Girls (TAAG), which aimed to examine multilevel factors related to the change of physical activity by following up a cohort of 783 girls over 10 years from adolescence to early adulthood. Our goal is to identify the intrinsic grouping of subjects with similar patterns of physical activity trajectories and the most relevant predictors within each group. The previous analyses conducted clustering and variable selection in two steps, while our new method can perform the tasks simultaneously. Within each cluster, a linear mixed-effects model (LMM) is fitted with a doubly penalized likelihood to induce sparsity for parameter estimation and effect selection. The large-sample joint properties are established, allowing the dimensions of both fixed and random effects to increase at an exponential rate of the sample size, with a general class of penalty functions. Assuming subjects are drawn from a Gaussian mixture distribution, model effects and cluster labels are estimated via a coordinate descent algorithm nested inside the Expectation-Maximization (EM) algorithm. Bayesian Information Criterion (BIC) is used to determine the optimal number of clusters and the values of tuning parameters. Our numerical studies show that the new method has satisfactory performance and is able to accommodate complex data with multilevel and/or longitudinal~effects.},
  langid = {english},
  keywords = {Adolescent,Adult,Algorithms,Bayes Theorem,Cluster Analysis,exponentially growing number of variables,Female,Humans,linear mixed-effects models,Linear Models,nonconcave penalty functions,Normal Distribution,simultaneous effects selection}
}

@article{zeileisModelBasedRecursivePartitioning2008,
  title = {Model-{{Based Recursive Partitioning}}},
  author = {Zeileis, Achim and Hothorn, Torsten and Hornik, Kurt},
  date = {2008-06},
  journaltitle = {Journal of Computational and Graphical Statistics},
  shortjournal = {Journal of Computational and Graphical Statistics},
  volume = {17},
  number = {2},
  pages = {492--514},
  issn = {1061-8600, 1537-2715},
  doi = {10.1198/106186008X319331},
  langid = {english},
  file = {files/14/Zeileis et al. - 2008 - Model-Based Recursive Partitioning.pdf}
}

@article{zhangHierarchicalDeeplearningNeural2021,
  title = {Hierarchical Deep-Learning Neural Networks: Finite Elements and Beyond},
  shorttitle = {Hierarchical Deep-Learning Neural Networks},
  author = {Zhang, Lei and Cheng, Lin and Li, Hengyang and Gao, Jiaying and Yu, Cheng and Domel, Reno and Yang, Yang and Tang, Shaoqiang and Liu, Wing Kam},
  date = {2021-01},
  journaltitle = {Computational Mechanics},
  shortjournal = {Comput Mech},
  volume = {67},
  number = {1},
  pages = {207--230},
  issn = {0178-7675, 1432-0924},
  doi = {10.1007/s00466-020-01928-9},
  abstract = {The hierarchical deep-learning neural network (HiDeNN) is systematically developed through the construction of structured deep neural networks (DNNs) in a hierarchical manner, and a special case of HiDeNN for representing Finite Element Method (or HiDeNN-FEM in short) is established. In HiDeNN-FEM, weights and biases are functions of the nodal positions, hence the training process in HiDeNN-FEM includes the optimization of the nodal coordinates. This is the spirit of r-adaptivity, and it increases both the local and global accuracy of the interpolants. By fixing the number of hidden layers and increasing the number of neurons by training the DNNs, rh-adaptivity can be achieved, which leads to further improvement of the accuracy for the solutions. The generalization of rational functions is achieved by the development of three fundamental building blocks of constructing deep hierarchical neural networks. The three building blocks are linear functions, multiplication, and inversion. With these building blocks, the class of deep learning interpolation functions are demonstrated for interpolation theories such as Lagrange polynomials, NURBS, isogeometric, reproducing kernel particle method, and others. In HiDeNNFEM, enrichment functions through the multiplication of neurons is equivalent to the enrichment in standard finite element methods, that is, generalized, extended, and partition of unity finite element methods. Numerical examples performed by HiDeNN-FEM exhibit reduced approximation error compared with the standard FEM. Finally, an outlook for the generalized HiDeNN to high-order continuity for multiple dimensions and topology optimizations are illustrated through the hierarchy of the proposed DNNs.},
  langid = {english},
  file = {files/99/Zhang et al. - 2021 - Hierarchical deep-learning neural networks finite elements and beyond.pdf}
}
